{
    "llm_config": {
        "model": "openai/gpt-3.5-turbo",
        "max_tokens": 2048,
        "temperature": 0.7,
        "top_p": 1.0
    },
    "local_config": {
        "tryb": "prezentacja",
        "styl": "precyzyjny",
        "stt": "faster_whisper",
        "tts": "coqui"
    }
}